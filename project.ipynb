{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: SVD using Fixed Point Iterations\n",
    "\n",
    "## Group members\n",
    "* Jake Swartwout: Trying to break the system\n",
    "* Lara Chunko\n",
    "* Yunhan Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We looked at a sample way of finding the SVD for a matrix. But, the method seems highly unstable and slow, so we thought we would compare it to standard packages and attempt to break it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to the repository: https://github.com/j2kun/svd/blob/master/svd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, this software performs the \"Singular Value Decomposition\" (SVD) of a matrix. This means that it is splitting any matrix A (it doesn't even need to be square) into 3 separate matrices. We represent it like this:\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "With the following properties:\n",
    "\n",
    "$U$ and $V$ have orthonormal columns\n",
    "\n",
    "$\\Sigma$ is a diagonal matrix\n",
    "\n",
    "This may seem familiar to diagonalization, as it does something similar. One of the main benefits however, is that our matrix A does not have to be square for SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svdMaster.svd import svd as testSVD\n",
    "from numpy.linalg import svd as npSVD\n",
    "from scipy.linalg import svd as scipySVD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing ours to standard software\n",
    "\n",
    "Comparing the runtimes of our SVD, numpy's svd, and Scipy's svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testSVD runtime:  0.0077245235443115234\n",
      "scipySVD runtime:  0.0046651363372802734\n",
      "npSVD runtime:  0.0046651363372802734\n"
     ]
    }
   ],
   "source": [
    "#test array\n",
    "A = np.random.rand(10,10) \n",
    "\n",
    "#applying testSVD\n",
    "start_t = time.time()\n",
    "test_sigma, test_U, test_VT = testSVD(A)\n",
    "end_t = time.time()\n",
    "test_time = end_t - start_t\n",
    "print(\"testSVD runtime: \", test_time)\n",
    "test_recombined = test_U @ np.diag(test_sigma) @ test_VT\n",
    "\n",
    "#applying scipySVD \n",
    "start_t = time.time()\n",
    "scipy_U, scipy_sigma, scipy_VT = scipySVD(A) \n",
    "end_t = time.time()\n",
    "scipy_time = end_t - start_t\n",
    "print(\"scipySVD runtime: \", scipy_time)\n",
    "scipy_recombined = scipy_U @ np.diag(scipy_sigma) @ scipy_VT\n",
    "\n",
    "#applying npSVD\n",
    "start_t = time.time()\n",
    "np_U, np_sigma, np_VT = npSVD(A)\n",
    "end_t = time.time()\n",
    "np_time = end_t - start_t\n",
    "print(\"npSVD runtime: \", scipy_time)\n",
    "np_recombined = np_U @ np.diag(np_sigma) @ np_VT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the recombined matrices among our software and the standard software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_scipy_recombined_difference =  3.933728343064047e-13\n",
      "test_np_recombined_difference =  3.933728343064047e-13\n",
      "scipy_np_recombined_difference =  0.0\n"
     ]
    }
   ],
   "source": [
    "#testing testSVD versus scipySVD\n",
    "#loop through and find the difference between the two versions\n",
    "test_scipy_recombined_difference = 0\n",
    "#column\n",
    "for i in range(len(test_recombined[0])):\n",
    "    #row\n",
    "    for j in range(len(test_recombined)):\n",
    "        #print(\"test \", test_recombined[i,j])\n",
    "        #print(\"scipy \", scipy_recombined[i,j])\n",
    "        test_scipy_recombined_difference += abs(test_recombined[i,j] - scipy_recombined[i,j])\n",
    "        \n",
    "print(\"test_scipy_recombined_difference = \", test_scipy_recombined_difference)\n",
    "\n",
    "#testing testSVD versus npSVD\n",
    "#loop through and find the difference between the two versions\n",
    "test_np_recombined_difference = 0\n",
    "#column\n",
    "for i in range(len(test_recombined[0])):\n",
    "    #row\n",
    "    for j in range(len(test_recombined)):\n",
    "        #print(\"test \", test_recombined[i,j])\n",
    "        #print(\"np \", np_recombined[i,j])\n",
    "        test_np_recombined_difference += abs(test_recombined[i,j] - np_recombined[i,j])\n",
    "        \n",
    "print(\"test_np_recombined_difference = \", test_np_recombined_difference)\n",
    "\n",
    "#testing scipySVD versus npSVD\n",
    "#loop through and find the difference between the two versions\n",
    "scipy_np_recombined_difference = 0\n",
    "#column\n",
    "for i in range(len(scipy_recombined[0])):\n",
    "    #row\n",
    "    for j in range(len(scipy_recombined)):\n",
    "        #print(\"scipy \", scipy_recombined[i,j])\n",
    "        #print(\"np \", np_recombined[i,j])\n",
    "        scipy_np_recombined_difference += abs(scipy_recombined[i,j] - np_recombined[i,j])\n",
    "\n",
    "print(\"scipy_np_recombined_difference = \", scipy_np_recombined_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talk more about these results in the conclusion at the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking it\n",
    "\n",
    "This method does not seem very robust, so we decided to look into a few ways to break it.\n",
    "\n",
    "The first step is to run several tests to get some averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_combine_test(matrix):\n",
    "    sigma, u, v = testSVD(A)\n",
    "    recombined = u @ np.diag(sigma) @ v\n",
    "    return recombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTests = 100\n",
    "asize = (10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline reconstruction error for a random (10, 20) matrix: 4.531714141673653e-15\n"
     ]
    }
   ],
   "source": [
    "norms = []\n",
    "for i in range(numTests):\n",
    "    A = np.random.rand(*asize)\n",
    "    Aprime = split_combine_test(A)\n",
    "    norms.append(np.linalg.norm(Aprime - A))\n",
    "baseline = np.mean(norms)\n",
    "print(\"Baseline reconstruction error for a random\", asize, \"matrix:\", baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. My first idea is to have two eigenvalues of the same value. This would mean that the program would not be able to choose one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with two same eigenvalues: 3.0638269040502948e-15\n",
      "Two same error : baseline error = 0.6760856506537638 : 1\n"
     ]
    }
   ],
   "source": [
    "norms = []\n",
    "for i in range(numTests):\n",
    "    #generate a random matrix\n",
    "    A = np.random.rand(*asize)\n",
    "    #decompose it\n",
    "    u, s, vt = npSVD(A, full_matrices=False)\n",
    "    #scale the first two\n",
    "    avg = (s[0] + s[1])/2\n",
    "    s[0] = avg\n",
    "    s[1] = avg\n",
    "    #reconstruct it\n",
    "    A = u @ np.diag(s) @ vt\n",
    "    #split and recombine\n",
    "    Aprime = split_combine_test(A)\n",
    "    norms.append(np.linalg.norm(Aprime - A))\n",
    "same = np.mean(norms)\n",
    "print(\"Error with two same eigenvalues:\", same)\n",
    "print(\"Two same error : baseline error =\", same / baseline, \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Another idea would be to have all of them be the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with two same eigenvalues: 1.3968471710286546e-15\n",
      "Two same error : baseline error = 0.30823814727924803 : 1\n"
     ]
    }
   ],
   "source": [
    "norms = []\n",
    "for i in range(numTests):\n",
    "    #generate a random matrix\n",
    "    A = np.random.rand(*asize)\n",
    "    #decompose it\n",
    "    u, s, vt = npSVD(A, full_matrices=False)\n",
    "    #average all of them\n",
    "    avg = np.mean(s)\n",
    "    s = [avg for item in s]\n",
    "    #reconstruct it\n",
    "    A = u @ np.diag(s) @ vt\n",
    "    #split and recombine\n",
    "    Aprime = split_combine_test(A)\n",
    "    norms.append(np.linalg.norm(Aprime - A))\n",
    "all_same = np.mean(norms)\n",
    "print(\"Error with two same eigenvalues:\", all_same)\n",
    "print(\"Two same error : baseline error =\", all_same / baseline, \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Or, the matrix could have all of it's columns be of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with two same eigenvalues: 4.293547837676208e-15\n",
      "Two same error : baseline error = 0.9474445438190227 : 1\n"
     ]
    }
   ],
   "source": [
    "norms = []\n",
    "for i in range(numTests):\n",
    "    #generate a random matrix\n",
    "    A = np.random.rand(*asize)\n",
    "    #scale everything\n",
    "    for i in range(len(A[0])):\n",
    "        A[:, i] /= np.linalg.norm(A[:, 0])\n",
    "    #split and recombine\n",
    "    Aprime = split_combine_test(A)\n",
    "    norms.append(np.linalg.norm(Aprime - A))\n",
    "len1 = np.mean(norms)\n",
    "print(\"Error with two same eigenvalues:\", len1)\n",
    "print(\"Two same error : baseline error =\", len1 / baseline, \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Or a matrix where two columns are just scaled versions of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with two same eigenvalues: 4.579761150626306e-15\n",
      "Two same error : baseline error = 1.0106023918214109 : 1\n"
     ]
    }
   ],
   "source": [
    "norms = []\n",
    "for i in range(numTests):\n",
    "    #generate a random matrix\n",
    "    A = np.random.rand(*asize)\n",
    "    A[:, 1] = A[:, 0] * np.random.rand()\n",
    "    #split and recombine\n",
    "    Aprime = split_combine_test(A)\n",
    "    norms.append(np.linalg.norm(Aprime - A))\n",
    "scaled = np.mean(norms)\n",
    "print(\"Error with two same eigenvalues:\", scaled)\n",
    "print(\"Two same error : baseline error =\", scaled / baseline, \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We noticed that scipy and numpy produce the same results, indicating that they use the same method to get their answer.\n",
    "\n",
    "Consistently, our software runs slower than the scipy/numpy software. So, we would not recommend using this software in a professional setting, as it would take much longer to get your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, all of these failed to break our system, meaning that it is likely pretty robust. Perhaps this is due to overall low accuracy to begin with, so small errors don't change it much. I would be interested in knowing why the error actually goes down for some of the methods, as I would estimate that it should be getting worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
